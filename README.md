# langgraph_research_assistant

ğŸ§  Streamlit Project  
ğŸ“„ AI Research Agent using Groq + LangGraph

ğŸ“Œ Project Overview

Welcome to my AI Research Agent! This web app allows you to input any research topic and automatically:

âœ… Plans the research  
âœ… Gathers key insights from the web  
âœ… Synthesizes the information using an LLM  
âœ… Summarizes findings into an executive brief  
âœ… *Provides citations and source URLs*  
âœ… Exports everything into a downloadable Markdown report

Itâ€™s powered by Groqâ€™s blazing-fast LLaMA3-70B model, built using LangGraph, and wrapped in an interactive Streamlit UI â€” perfect for students, researchers, or anyone curious!

---

ğŸš€ How I Built & Ran the App (Step-by-Step)

Hereâ€™s the exact process I followed to bring this research assistant to life ğŸ‘‡

1. Created a project folder: ai_research_agent

2. Added the main code files:
    - app.py: Streamlit frontend
    - graph_builder.py: LangGraph nodes for planning, searching, and summarizing

3. Created a .env file to store my API keys:
   GROQ_API_KEY=your_groq_api_key  
   TAVILY_API_KEY=your_tavily_api_key

4. Created a requirements.txt with these dependencies:
   streamlit  
   langchain  
   langgraph  
   langchain-groq  
   tavily-python  
   jinja2  
   python-dotenv

5. Installed everything using:
   pip install -r requirements.txt

6. Launched the Streamlit app:
   streamlit run app.py

7. Opened it in my browser:
   http://localhost:8501

---

ğŸ” GitHub Upload Steps

1. Created a new repository on GitHub
2. Opened terminal in my project folder
3. Ran:
   git init  
   git add .  
   git commit -m "Add AI Research Agent with LangGraph and Groq"  
   git remote add origin https://github.com/your-username/your-repo-name.git  
   git push -u origin main

Replace your-username and your-repo-name with your actual GitHub details.

---

ğŸ“ Project Folder Structure

ğŸ“¦ ai_research_agent  
â”£ ğŸ“„ app.py â†’ Streamlit UI + Graph Runner  
â”£ ğŸ“„ graph_builder.py â†’ LangGraph nodes: PLAN â†’ SEARCH â†’ RETRIEVE â†’ SYNTHESIZE â†’ SUMMARY â†’ REPORT  
â”£ ğŸ“„ report_template.md â†’ Jinja2 template for final report  
â”£ ğŸ“„ requirements.txt â†’ Python dependencies  
â”£ ğŸ“„ .env â†’ API keys (excluded from Git)  
â”£ ğŸ“„ README.md â†’ Youâ€™re reading it!  
â”— ğŸ“„ LICENSE â†’ MIT License

---

ğŸ’¡ What the App Can Do

âœ” Accepts any research topic  
âœ” Breaks it into sub-questions  
âœ” Uses Tavily API to perform advanced web search  
âœ” Extracts and retrieves top source content  
âœ” Synthesizes answers via Groq LLaMA3-70B  
âœ” *Displays source citations under every answer*  
âœ” Summarizes all findings and generates a full Markdown report  
âœ” Allows the report to be downloaded in one click

---

ğŸ“š Citation Support

The app collects the top 3 URLs for each sub-question from Tavily's search engine. These source URLs are:

- Included under the "Sources" section in the Streamlit app
- Added directly into the generated Markdown report for proper citation
- Help trace each insight back to the original source

âœ… This ensures transparency and supports academic/research use cases.

---

âœ¨ Tech Stack Used

- *Streamlit* â€” For the interactive UI
- *Groq (LLaMA3-70B)* â€” LLM for question generation and synthesis
- *LangGraph* â€” Node-based workflow orchestration
- *LangChain* â€” Agent tools + memory
- *Tavily API* â€” For web search and content extraction
- *Jinja2* â€” For Markdown templating
- *Python-dotenv* â€” For secure key management

---

ğŸ‘©â€ğŸ’» Created By

*Raama Katragadda*
*Ushmitha Annapaneni*  
*Vedasri Narla*
If you found this project helpful, feel free to star â­ or fork ğŸ´ it on GitHub!

---

ğŸ“„ License

MIT License â€” Free to use, modify, and distribute.
